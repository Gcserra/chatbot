from transformers import pipeline
import gradio as gr

# Daha gÃ¼Ã§lÃ¼ ama yine kÃ¼Ã§Ã¼k bir model
generator = pipeline("text-generation", model="distilgpt2")

# Few-shot Ã¶rnekler
few_shot_examples = (
    "Soru: Python nedir?\nCevap: Python, aÃ§Ä±k kaynaklÄ± ve Ã§ok yÃ¶nlÃ¼ bir programlama dilidir.\n"
    "Soru: Yapay zeka nedir?\nCevap: Makinelerin dÃ¼ÅŸÃ¼nme ve Ã¶ÄŸrenme yeteneÄŸi kazanmasÄ±nÄ± saÄŸlayan teknolojidir.\n"
    "Soru: Veri bilimi nedir?\nCevap: Verileri analiz ederek anlamlÄ± bilgi elde etme bilimidir.\n"
)

# Chat fonksiyonu (uyumlu hale getirildi)
def chat_function(message, history):
    prompt = few_shot_examples + f"Soru: {message}\nCevap:"
    output = generator(prompt, max_new_tokens=60, do_sample=True, temperature=0.7)
    answer = output[0]['generated_text'].split("Cevap:")[-1].strip()
    return answer

# Gradio arayÃ¼zÃ¼
gr.ChatInterface(
    fn=chat_function,
    title="ğŸ§  Few-shot Slaybot",
    theme="soft",
    examples=["Python nedir?", "Veri bilimi nedir?", "En bÃ¼yÃ¼k gezegen nedir?"]
).launch()

